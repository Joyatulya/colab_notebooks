{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joyatulya/colab_notebooks/blob/main/CXR_Lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZIlGcsYVpSq"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br9ixfdbk_Td"
      },
      "outputs": [],
      "source": [
        "!sudo apt install -q cadaver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsMVZH3x9010"
      },
      "outputs": [],
      "source": [
        "kaggle datasets download -d raddar/chest-xrays-tuberculosis-from-india"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAlBSBzgbIJT"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade pandas==1.2.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g06LLJBwwZyM"
      },
      "source": [
        "#Enviornment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRF20yX6hHr9"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Joyatulya/utils.git\n",
        "!git clone https://github.com/Joyatulya/torchvision_custom.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4HHMTpohNM6"
      },
      "outputs": [],
      "source": [
        "from utils.enviornmet_setup import *\n",
        "# mount_drive()\n",
        "!mkdir /root/.kaggle\n",
        "config_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4mUqqWyOp8p"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d xhlulu/vinbigdata-chest-xray-resized-png-1024x1024\n",
        "!kaggle datasets download -d raddar/tuberculosis-chest-xrays-montgomery\n",
        "!kaggle datasets download -d raddar/tuberculosis-chest-xrays-shenzhen\n",
        "!kaggle datasets download -d nih-chest-xrays/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkhCeaZgiyuz"
      },
      "outputs": [],
      "source": [
        "!mkdir ./nih\n",
        "!unzip -qq data.zip -d ./nih\n",
        "!cp ./drive/MyDrive/cxr/nih/full_working_nih_df.csv ./sample/full_working_nih_df.csv\n",
        "!rm data.zip\n",
        "!cp ./drive/MyDrive/cxr/nih/masks_nih.zip ./masks_nih.zip\n",
        "!mkdir nih\n",
        "!unzip -qq masks_nih.zip -d masks_nih\n",
        "!rm masks_nih.zip\n",
        "\n",
        "!mkdir ./vinbigdata\n",
        "!unzip -q vinbigdata-chest-xray-resized-png-1024x1024.zip -d ./vinbigdata\n",
        "!rm vinbigdata-chest-xray-resized-png-1024x1024.zip\n",
        "\n",
        "!cp -r ./drive/MyDrive/cxr/vinbigdata/* ./vinbigdata\n",
        "\n",
        "!mkdir montgomery\n",
        "!unzip -q tuberculosis-chest-xrays-montgomery.zip  -d ./montgomery/\n",
        "!rm tuberculosis-chest-xrays-montgomery.zip\n",
        "\n",
        "!mkdir shenzhen\n",
        "!unzip -q tuberculosis-chest-xrays-shenzhen.zip -d ./shenzhen/\n",
        "!rm tuberculosis-chest-xrays-shenzhen.zip\n",
        "\n",
        "!mkdir combined\n",
        "!cp -r ./drive/MyDrive/cxr/tb/* ./combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiNh55y2kenj"
      },
      "outputs": [],
      "source": [
        "\n",
        "!cp ./drive/MyDrive/cxr/nih/worst_cxr.txt ./worst_cxr.txt\n",
        "!cp ./drive/MyDrive/cxr/nih/last_cxr.txt ./last_cxr.txt\n",
        "# !cp ./drive/MyDrive/predicted_full_nih.csv ./predicted_full_nih.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFU0mGv7wdU4"
      },
      "source": [
        "#Libraries & Hyper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_DMzNl9Svmk"
      },
      "outputs": [],
      "source": [
        "!pip install -q wandb pytorch-lightning transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXdNykNksK5o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wandb\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import pathlib\n",
        "import h5py\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, Resize\n",
        "from torch import nn\n",
        "import cv2\n",
        "\n",
        "from torch.utils import data\n",
        "import pytorch_lightning as pl\n",
        "pl.seed_everything(1996)\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79i_EsMDrbhI"
      },
      "outputs": [],
      "source": [
        "CHANNELS  = 3\n",
        "IMG_SIZE = (300,300,CHANNELS)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "BASE_FOLDER = os.path.join('drive', 'MyDrive', 'cxr')\n",
        "\n",
        "AUX_DATA_COLUMNS = ['age', 'position','ct_ratio', 'ct_area', 'right_cp_angle', 'right_cp_angle_direction',\n",
        "                    'left_cp_angle', 'left_cp_angle_direction', 'cp_rel_position',\n",
        "                    'height_width_ratio', 'area_ratio', 'vertical_span_ratio', 'Gender']\n",
        "\n",
        "categorical_cols = ['Gender', 'position']\n",
        "\n",
        "numerical_cols = ['ct_ratio','ct_area','right_cp_angle','left_cp_angle',\n",
        "                  'cp_rel_position','height_width_ratio','area_ratio','vertical_span_ratio']\n",
        "\n",
        "# Have removed hernia from here\n",
        "PATHOLOGY_LIST = ['Cardiomegaly','Emphysema','Effusion',\n",
        "                  'Pneumothorax','Mass','Edema','Consolidation',\n",
        "                  'Fibrosis',]\n",
        "\n",
        "configs = dict(\n",
        "    data_flag = 'nih_full_pytorch',\n",
        "    channels = CHANNELS,\n",
        "    img_shape = IMG_SIZE,\n",
        "    class_names = PATHOLOGY_LIST,\n",
        ")\n",
        "\n",
        "print(f\"Using {device} accelaration\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5QDGNH27ieR"
      },
      "source": [
        "#Loading and Cleaning data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cITDXG3kt6-7"
      },
      "source": [
        "##Accessory Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aOhNSURwMxP"
      },
      "outputs": [],
      "source": [
        "# vin_df = pd.read_csv('./vinbigdata/train.csv')\n",
        "# column_list = ['image_id', 'class_name',]\n",
        "# vin_df = vin_df.loc[:,column_list]\n",
        "# images_vin = {os.path.basename(x).split('.')[0]: x for x in \n",
        "#                    glob(os.path.join('./vinbigdata/', '*', '*.png'))}\n",
        "# vin_df['path'] = vin_df[\"image_id\"].map(images_vin.get)\n",
        "\n",
        "# def get_all_disease(image_id):\n",
        "#   total_disease = vin_df[vin_df.image_id == image_id].class_name.values\n",
        "#   total_disease = '|'.join(total_disease)\n",
        "#   return total_disease\n",
        "\n",
        "# vin_df['findings'] = vin_df['image_id'].apply(get_all_disease)\n",
        "# working_vin_df = vin_df.loc[:,['image_id','path','findings']].drop_duplicates()\n",
        "# working_vin_df['masks'] = './vinbigdata/masks/' + working_vin_df['image_id'] + '_mask.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8zZk7VQ8pjG"
      },
      "outputs": [],
      "source": [
        "# vin_aux_df = pd.read_csv('./vinbigdata/vinbigdata_aux.csv')\n",
        "# vin_aux_df.rename(columns = {'image_index' : 'image_id'}, inplace = True)\n",
        "# working_vin_df = pd.merge(working_vin_df, vin_aux_df, on = 'image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyS1KNsi_9ti"
      },
      "outputs": [],
      "source": [
        "resize = T.Resize((384,384))\n",
        "threshold = nn.Threshold(40, 0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H28FIBg16ZrQ"
      },
      "outputs": [],
      "source": [
        "example = working_combined_df.iloc[np.random.randint(0,len(working_combined_df)),:]\n",
        "img = read_image(example.path, ImageReadMode.RGB)\n",
        "img = resize(img)\n",
        "mask = read_image(example.masks, ImageReadMode.GRAY)\n",
        "mask = resize(mask)\n",
        "mask = threshold(mask)\n",
        "fig, ax = plt.subplots(1,3,figsize = (30,8))\n",
        "ax = ax.flatten()\n",
        "ax[0].imshow(img[0,:], cmap = 'gray')\n",
        "ax[1].imshow(mask[0,:], cmap = 'gray')\n",
        "plt.show()\n",
        "print(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WT9vbEjHBzBl"
      },
      "outputs": [],
      "source": [
        "def boundaries_lung(mask, margin = 20):\n",
        "  # blank = torch.zeros((384,384))\n",
        "  mask = read_image(mask, ImageReadMode.GRAY)\n",
        "  mask = resize(mask)\n",
        "  mask = threshold(mask)\n",
        "  mask = mask[0,:]\n",
        "  cols = mask.any(0).nonzero()\n",
        "  rows = mask.any(1).nonzero()\n",
        "  top = rows[0].item() - margin\n",
        "  bottom = rows[-1].item() + margin + 3\n",
        "  left = cols[0].item() - margin\n",
        "  right = cols[-1].item() + margin\n",
        "  # blank[top : bottom, left : right] = 1\n",
        "  return [top, bottom, left, right]\n",
        "# boundaries_lung(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-Ic67v1JzTl"
      },
      "outputs": [],
      "source": [
        "boundaries_lung(combined_df.masks.values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoZjRkITJKMx"
      },
      "outputs": [],
      "source": [
        "# combined_df['top'], combined_df['bottom'], combined_df['left'], combined_df['right'] = 0,0,0,0\n",
        "# combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UefI6cJMYGt"
      },
      "outputs": [],
      "source": [
        "values = full_df['masks'].apply(boundaries_lung)\n",
        "tops, bottoms, lefts, rights = [],[],[],[]\n",
        "for val in values:\n",
        "  tops.append(val[0])\n",
        "  bottoms.append(val[1])\n",
        "  lefts.append(val[2])\n",
        "  rights.append(val[3])\n",
        "full_df['top'] = tops\n",
        "full_df['bottom'] = bottoms\n",
        "full_df['left'] = lefts\n",
        "full_df['right'] = rights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8Nl5dkpJgzG"
      },
      "outputs": [],
      "source": [
        "working_vin_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6jzcDvSNkdN"
      },
      "outputs": [],
      "source": [
        "full_df.to_csv('full_working_nih_df.csv')\n",
        "!cp ./full_working_nih_df.csv ./drive/MyDrive/cxr/nih/full_working_nih_df.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydyBuyRZEHze"
      },
      "outputs": [],
      "source": [
        "# top, bottom, left, right = boundaries_lung(mask)\n",
        "cxr_mask = boundaries_lung(mask)\n",
        "img_masked = img * cxr_mask\n",
        "# img = img[:,top : bottom, left : right]\n",
        "# img = img[:,left : right, top : bottom]\n",
        "plt.imshow(img_masked[0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YfrKVtR1O41"
      },
      "outputs": [],
      "source": [
        "all_strings = '|'.join(working_vin_df.findings).split('|')\n",
        "pd.Series(all_strings).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxnvfGURHid9"
      },
      "outputs": [],
      "source": [
        "# mont_df = pd.read_csv('./montgomery/montgomery_metadata.csv')\n",
        "# images_mont = {os.path.basename(x): x for x in \n",
        "#                    glob(os.path.join('./montgomery/', 'images','images', '*.png'))}\n",
        "# mont_df['path'] = mont_df['study_id'].apply(images_mont.get)\n",
        "# mont_df.rename(columns = {'study_id' : 'image_id'}, inplace = True)\n",
        "\n",
        "# shen_df = pd.read_csv('./shenzhen/shenzhen_metadata.csv')\n",
        "# images_shen = {os.path.basename(x): x for x in \n",
        "#                    glob(os.path.join('./shenzhen/', 'images','images', '*.png'))}\n",
        "# shen_df['path'] = shen_df['study_id'].apply(images_shen.get)\n",
        "# shen_df.rename(columns = {'study_id' : 'image_id','sex' : 'gender'}, inplace = True)\n",
        "\n",
        "# combined_df = pd.concat((shen_df,mont_df))\n",
        "# combined_df.rename(columns = {'findings' : 'label'}, inplace = True)\n",
        "\n",
        "# def parse_tb_findings(label):\n",
        "#   if label == 'normal':\n",
        "#     return 'No Finding'\n",
        "#   findings = ['Consolidation']\n",
        "#   label = str(label).lower()\n",
        "#   if 'pneumot' in label:\n",
        "#     findings.append('Pneumothorax')\n",
        "#   if 'atelec' in label:\n",
        "#     findings.append('Atelectasis')\n",
        "#   if 'effusion' in label:\n",
        "#     findings.append('Effusion')\n",
        "#   if 'fibr' in label or 'scar' in label or 'calc' in label:\n",
        "#     findings.append('Fibrosis')\n",
        "#   if 'copd' in label or 'emphy' in label:\n",
        "#     findings.append('Emphysema')\n",
        "#   return '|'.join(findings)\n",
        "\n",
        "# combined_df['findings'] = combined_df.label.apply(parse_tb_findings)\n",
        "# combined_df.drop(labels = 'label',axis = 1, inplace=True)\n",
        "# combined_df['masks'] = './combined/masks/' + combined_df['image_id'] + '_mask.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8nRGt1S-EsR"
      },
      "outputs": [],
      "source": [
        "# combined_aux_df = pd.read_csv('./combined/tb_aux.csv')\n",
        "# combined_aux_df.rename(columns = {'image_index' : 'image_id'}, inplace = True)\n",
        "# working_combined_df = pd.merge(combined_df, combined_aux_df, on = 'image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaGWKKpqHkQW"
      },
      "outputs": [],
      "source": [
        "# raw_df = pd.read_csv(BASE_FOLDER + '/nih/Data_entry_2017.csv')\n",
        "# raw_df = raw_df.drop('Unnamed: 11', axis = 1)\n",
        "# raw_df.columns = ['image_id','findings', 'f/u', 'pt_id',\n",
        "#                   'age', 'gender', 'position',\n",
        "#                   'Width','Height', 'x', 'y']\n",
        "\n",
        "# all_image_paths = {os.path.basename(x): x for x in \n",
        "                  #  glob(os.path.join('.', 'images*', '*', '*.png'))}\n",
        "# raw_df['path'] = raw_df['image_index'].map(all_image_paths.get)\n",
        "                   \n",
        "# print('Scans found:', len(all_image_paths), ', Total Headers', raw_df.shape[0])\n",
        "# raw_df['masks'] = './masks_nih/masks/' + raw_df['image_id'] + '_mask.png'\n",
        "# raw_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0H1Hrt1Q9wT"
      },
      "outputs": [],
      "source": [
        "# raw_df = pd.read_csv(BASE_FOLDER + '/nih/predicted_full_nih.csv')\n",
        "# aux_df = pd.read_csv(BASE_FOLDER + '/nih/predicted_full_nih.csv')\n",
        "# full_df = pd.merge(raw_df, aux_df, on = 'image_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzuhrsuLejnS"
      },
      "outputs": [],
      "source": [
        "# aux_df = pd.read_csv('./nih/predicted_full_nih.csv')\n",
        "# aux_df = aux_df.iloc[:, 2:]\n",
        "# full_df = pd.merge(raw_df, aux_df, how = 'inner', on = 'image_index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRvQAEVvt-gy"
      },
      "source": [
        "##Main Shit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h2pexZcqaIm"
      },
      "outputs": [],
      "source": [
        "vin_df = pd.read_csv('./vinbigdata/full_working_vin_df.csv')\n",
        "tb_df = pd.read_csv('./combined/full_working_combined_df.csv')\n",
        "\n",
        "working_df = pd.read_csv(BASE_FOLDER + '/nih/full_working_nih_df.csv')\n",
        "all_image_paths = {os.path.basename(x): x for x in \n",
        "                   glob(os.path.join('./nih', 'images*', '*', '*.png'))}\n",
        "working_df['path'] = working_df['image_id'].map(all_image_paths.get)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tb_df.sample(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Senx7OkdHYQ3",
        "outputId": "8543d166-bd2d-4052-9d52-dc6a1e482e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              image_id  gender  age  \\\n",
              "602  CHNCXR_0603_1.png    Male   60   \n",
              "695  MCUCXR_0047_0.png  Female   35   \n",
              "\n",
              "                                             path       findings  \\\n",
              "602    ./shenzhen/images/images/CHNCXR_0603_1.png  Consolidation   \n",
              "695  ./montgomery/images/images/MCUCXR_0047_0.png     No Finding   \n",
              "\n",
              "                                           masks  ct_ratio  ct_area  \\\n",
              "602  ./combined/masks/CHNCXR_0603_1.png_mask.png     0.454    0.366   \n",
              "695  ./combined/masks/MCUCXR_0047_0.png_mask.png     0.474    0.338   \n",
              "\n",
              "     right_cp_angle  right_cp_angle_direction  left_cp_angle  \\\n",
              "602       58.671307                 79.099295      54.415626   \n",
              "695       50.782392                 59.081264      50.948461   \n",
              "\n",
              "     left_cp_angle_direction  cp_rel_position  height_width_ratio  area_ratio  \\\n",
              "602                65.082797            1.155               0.817       3.447   \n",
              "695                67.461443            1.000               0.734       1.291   \n",
              "\n",
              "     vertical_span_ratio  top  bottom  left  right  \n",
              "602                1.509   35     326     5    363  \n",
              "695                0.980   15     285     3    356  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33a0e624-1763-4e86-9f7e-c331c466f6b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>path</th>\n",
              "      <th>findings</th>\n",
              "      <th>masks</th>\n",
              "      <th>ct_ratio</th>\n",
              "      <th>ct_area</th>\n",
              "      <th>right_cp_angle</th>\n",
              "      <th>right_cp_angle_direction</th>\n",
              "      <th>left_cp_angle</th>\n",
              "      <th>left_cp_angle_direction</th>\n",
              "      <th>cp_rel_position</th>\n",
              "      <th>height_width_ratio</th>\n",
              "      <th>area_ratio</th>\n",
              "      <th>vertical_span_ratio</th>\n",
              "      <th>top</th>\n",
              "      <th>bottom</th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>CHNCXR_0603_1.png</td>\n",
              "      <td>Male</td>\n",
              "      <td>60</td>\n",
              "      <td>./shenzhen/images/images/CHNCXR_0603_1.png</td>\n",
              "      <td>Consolidation</td>\n",
              "      <td>./combined/masks/CHNCXR_0603_1.png_mask.png</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.366</td>\n",
              "      <td>58.671307</td>\n",
              "      <td>79.099295</td>\n",
              "      <td>54.415626</td>\n",
              "      <td>65.082797</td>\n",
              "      <td>1.155</td>\n",
              "      <td>0.817</td>\n",
              "      <td>3.447</td>\n",
              "      <td>1.509</td>\n",
              "      <td>35</td>\n",
              "      <td>326</td>\n",
              "      <td>5</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>MCUCXR_0047_0.png</td>\n",
              "      <td>Female</td>\n",
              "      <td>35</td>\n",
              "      <td>./montgomery/images/images/MCUCXR_0047_0.png</td>\n",
              "      <td>No Finding</td>\n",
              "      <td>./combined/masks/MCUCXR_0047_0.png_mask.png</td>\n",
              "      <td>0.474</td>\n",
              "      <td>0.338</td>\n",
              "      <td>50.782392</td>\n",
              "      <td>59.081264</td>\n",
              "      <td>50.948461</td>\n",
              "      <td>67.461443</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.734</td>\n",
              "      <td>1.291</td>\n",
              "      <td>0.980</td>\n",
              "      <td>15</td>\n",
              "      <td>285</td>\n",
              "      <td>3</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a0e624-1763-4e86-9f7e-c331c466f6b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33a0e624-1763-4e86-9f7e-c331c466f6b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33a0e624-1763-4e86-9f7e-c331c466f6b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from PIL import Image\n",
        "class AddGaussianNoise(nn.Module):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "                                                                      \n",
        "class CustomDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.path = df.path.values\n",
        "    self.image_id = df.image_id.values\n",
        "    self.transform = T.Compose([\n",
        "      # T.PILToTensor(),\n",
        "                                T.Resize((284,284)),\n",
        "                                T.RandomAutocontrast(0.2), \n",
        "                                T.RandomAffine(\n",
        "                                    degrees = 15,\n",
        "                                    translate =  (.09,.09),\n",
        "                                    scale = (.86, 1.20),\n",
        "                                    shear =  9\n",
        "                                ),\n",
        "                                AddGaussianNoise(0,0.013)\n",
        "                                                      ])\n",
        "  def __len__(self):\n",
        "    return len(self.path)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path =  self.path[idx]\n",
        "    img_name = self.image_id[idx]\n",
        "    # img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # img = np.expand_dims(img,0)\n",
        "    # try:\n",
        "      # img = torch.from_numpy(img)\n",
        "    # except TypeError as e:\n",
        "      # print('One Error')\n",
        "      # img = torch.ones((1,284,284))\n",
        "      # return img, 'error'\n",
        "    img = read_image(img_path, ImageReadMode.GRAY)\n",
        "    img = self.transform(img)\n",
        "    return img,img_name\n",
        "\n",
        "base = 'nih_' \n",
        "train_ds = CustomDataset(working_df)\n",
        "train_dataloader = data.DataLoader(train_ds, batch_size = len(train_ds) // 16)\n",
        "# img, label = next(iter(train_dataloader))\n",
        "for i, (img,label) in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
        "  i = str(i)\n",
        "  try:\n",
        "    with h5py.File(f'{base + i}.h5', 'w') as f:\n",
        "      f.create_dataset('img', data = img.numpy())\n",
        "      f.create_dataset('name', data = label)\n",
        "    shutil.copy(f'{base + i}.h5', f'./drive/MyDrive/padchest/{base}/{base + i}.h5')\n",
        "  except TypeError as e:\n",
        "    print(f'Error in Batch {base + i}')\n",
        "    raise e\n",
        "  # print(\"this ran too\")\n",
        "  os.remove(f'./{base + i}.h5')\n",
        "  # os.remove(f'./{base + i}.zip')\n",
        "  # shutil.rmtree(f'./{base + i}_img')"
      ],
      "metadata": {
        "id": "Dg2RHZCHF6hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label[:2], tb_df.image_id.values[:2]\n",
        "plt.imshow(img[0,0,:])\n",
        "plt.show()\n",
        "img_ = read_image(tb_df.path[0])\n",
        "plt.imshow(img_[0])\n",
        "# img_.shape"
      ],
      "metadata": {
        "id": "sYQTw6hDJ6XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g5B4Qiuygk1"
      },
      "outputs": [],
      "source": [
        "def standardise_df(df):\n",
        "  working_df = df.copy()\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Infiltration','Consolidation')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Pneumonia','Consolidation')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Atelectasis','Consolidation')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Nodule/Mass','Mass')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Nodule','Mass')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Lung Opacity','Mass')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Pulmonary fibrosis','Fibrosis')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('ILD','Fibrosis')\n",
        "  working_df['findings'] = working_df['findings'].str.replace('Pleural effusion', 'Effusion')\n",
        "  \n",
        "  return working_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPSH7wcdBiTG"
      },
      "outputs": [],
      "source": [
        "working_df = standardise_df(working_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww04iwjNsTDy"
      },
      "outputs": [],
      "source": [
        "with open(BASE_FOLDER + '/updated_worst_cxr.txt', 'r') as f:\n",
        "  worst_cxr = f.read().split('\\n')\n",
        "worst_cxr = worst_cxr[:-1]\n",
        "worst_cxr = set(worst_cxr)\n",
        "worst_cxr = np.array([*worst_cxr])\n",
        "worst_cxr = worst_cxr.astype('int')\n",
        "\n",
        "with open(BASE_FOLDER + '/updated_last_cxr.txt', 'r') as f:\n",
        "  last_cxr = f.read().split('\\n')\n",
        "last_cxr = last_cxr[:-1]\n",
        "last_cxr = set(last_cxr)\n",
        "last_cxr = np.array([*last_cxr])\n",
        "last_cxr = last_cxr.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0C0TnNOnWUo"
      },
      "outputs": [],
      "source": [
        "# For Patients whose all the images were bad\n",
        "num = 0\n",
        "for sick_pt_id in worst_cxr:\n",
        "  _df = working_df[working_df['pt_id'] == sick_pt_id]\n",
        "  nf_cxr = _df[_df['findings'] == 'No Finding']\n",
        "  f_cxr = _df[_df['findings'] != 'No Finding']\n",
        "  nf_cxr_idx = nf_cxr.index.values\n",
        "  all_findings = f_cxr['findings'].values\n",
        "  all_findings = '|'.join(all_findings).split('|')\n",
        "  all_findings = pd.Series(all_findings)\n",
        "  n_findings = all_findings.size\n",
        "  findings = all_findings.value_counts()\n",
        "  \n",
        "  # Percentage of labels out of all the findings\n",
        "  perc_findings = findings / n_findings * 100\n",
        "\n",
        "  mc_diseases = []\n",
        "  for i,j in perc_findings.iteritems():\n",
        "    if j > 20:\n",
        "      mc_diseases.append(i)\n",
        "      \n",
        "  joined_disease = '|'.join(mc_diseases)\n",
        "  for i in nf_cxr_idx:\n",
        "    if len(mc_diseases) > 0:\n",
        "      num += 1\n",
        "      working_df.at[i, 'findings'] = joined_disease\n",
        "    else:\n",
        "      working_df.at[i, 'findings'] = 'No Finding'\n",
        "print(num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1KEO2uMsDqX"
      },
      "outputs": [],
      "source": [
        "# For the patients whose first no finding images were okay\n",
        "i = 0\n",
        "NUM_REVIEWED = 951\n",
        "follow_up_patients = working_df['pt_id'].value_counts().index.values\n",
        "reviewed_fu = set(follow_up_patients[:NUM_REVIEWED])\n",
        "last_cxr_set = set(last_cxr)\n",
        "worst_cxr_set = set(worst_cxr)\n",
        "forward_fu = reviewed_fu - last_cxr_set\n",
        "forward_fu = forward_fu - worst_cxr_set\n",
        "\n",
        "for forward_pt in forward_fu:\n",
        "  working_df = working_df.reset_index(drop = True)\n",
        "  _df = working_df[working_df['pt_id'] == forward_pt]\n",
        "  nf_cxr = _df[_df['findings'] == 'No Finding']\n",
        "  idx = nf_cxr.index.values\n",
        "  i += len(idx) - 1\n",
        "  working_df = working_df.drop(index = idx[1:])\n",
        "\n",
        "print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkm2VtWIpbgh"
      },
      "outputs": [],
      "source": [
        "# For all patients whose last images were okay\n",
        "i = 0\n",
        "for last_pt in last_cxr:\n",
        "  working_df = working_df.reset_index(drop = True)\n",
        "  _df = working_df[working_df['pt_id'] == last_pt]\n",
        "  nf_cxr = _df[_df['findings'] == 'No Finding']\n",
        "  idx = nf_cxr.index.values[::-1]\n",
        "  i += len(idx) - 1\n",
        "  working_df = working_df.drop(index = idx[1:])\n",
        "print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZrwct_W36cK"
      },
      "source": [
        "#####Dropping with the help of Lung Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0kb4zTGtGkJ"
      },
      "outputs": [],
      "source": [
        "def show_grid_img_df(df):\n",
        "  fig, ax = plt.subplots(4,4, figsize = (15,15))\n",
        "  ax = ax.flatten()\n",
        "  print('Length of df ', len(df))\n",
        "  df = df.sample(frac = 1.)\n",
        "  for i in range(16):\n",
        "    img = process_img(df.path.values[i])\n",
        "    ax[i].imshow(img, cmap = 'gray')\n",
        "    ax[i].set_xlabel([])\n",
        "    ax[i].set_ylabel([])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15CFLR1rnGMT"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_low_ctr = working_df[(working_df['ct_ratio'] < .24) & (working_df['findings'] == 'No Finding')]['position']\n",
        "working_df = working_df.drop(index = nf_low_ctr.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1HlX1pgodSY"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_low_cta = working_df[(working_df['ct_area'] < .17) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_low_cta.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lF9EEplpmDH"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_high_ctr = working_df[(working_df['ct_ratio'] > .68) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_high_ctr.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ocLmFCqXGA"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_high_cta = working_df[(working_df['ct_area'] > .68) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_high_cta.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGPU4egWq3Dl"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_low_lung_area = working_df[(working_df['area_ratio'] < .55) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_low_lung_area.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFTkx7iFrcm0"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_high_lung_area = working_df[(working_df['area_ratio'] > 1.85) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_high_lung_area.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4tdGkPNsEAN"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_high_vs = working_df[(working_df['vertical_span_ratio'] > 1.45) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_high_vs.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bLCQnT1sshu"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_low_vs = working_df[(working_df['vertical_span_ratio'] < .65) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_low_vs.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUQ4bc3ZumYn"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_low_cp_pos = working_df[(working_df['cp_rel_position'] < .7) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_low_cp_pos.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGo-2VlvvNW7"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_high_cp_pos = working_df[(working_df['cp_rel_position'] > 1.3) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_high_cp_pos.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm0QnFCNvnYl"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_low_hw = working_df[(working_df['height_width_ratio'] < .55) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_low_hw.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocfo4wUMxdIL"
      },
      "outputs": [],
      "source": [
        "# working_df = working_df.reset_index(drop = True)\n",
        "# nf_high_hw = working_df[(working_df['height_width_ratio'] > 1.5) & (working_df['findings'] == 'No Finding')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq3OQVUnx5mS"
      },
      "outputs": [],
      "source": [
        "working_df = working_df.reset_index(drop = True)\n",
        "nf_high_cp_angle =  working_df[((working_df['left_cp_angle'] > 145) | (working_df['right_cp_angle'] > 145)) & (working_df['findings'] == 'No Finding')]\n",
        "working_df = working_df.drop(index = nf_high_cp_angle.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOdnnoxeBIXm"
      },
      "source": [
        "###Cleaning Data\n",
        "\n",
        "While cleaning the data we have to make sure that we first replace all the relevant values and only after that we drop them or we would have to unnecessarily have to change the indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbQnYfMpTPbD"
      },
      "outputs": [],
      "source": [
        "old_people = working_df[working_df['age'] > 100]\n",
        "for people in old_people.itertuples():\n",
        "  if people.age == 0:\n",
        "    age = 47\n",
        "  else:\n",
        "    age = working_df[working_df['pt_id'] == people.pt_id]['age'].min()\n",
        "  working_df.at[people.Index, 'age'] = age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdnyf7_UbBZ8"
      },
      "outputs": [],
      "source": [
        "working_df['No Findings'] = working_df['findings'].apply(lambda x: 0 if 'No Finding' in x else 1)\n",
        "working_df = working_df.drop(['No Findings'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O61YQUZz7ieX"
      },
      "source": [
        "###Constructing dataframes of all the specific diseases separately so that I'm able to oversample them accordingly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb69E4A0LWWd"
      },
      "source": [
        "#### I can maybe get out all the auto correlation of the different labels to see what are the chances of  a few diseasesa occuring together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZTryTEi9O_p"
      },
      "outputs": [],
      "source": [
        "working_vin_df = standardise_df(vin_df)\n",
        "working_tb_df = standardise_df(tb_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJND6O4Kidyp"
      },
      "outputs": [],
      "source": [
        "for pathology in PATHOLOGY_LIST :\n",
        "    working_df[pathology] = working_df['findings'].apply(lambda x: 1. if pathology in x else 0.)\n",
        "    working_vin_df[pathology] = working_vin_df['findings'].apply(lambda x: 1. if pathology in x else 0.)\n",
        "    working_tb_df[pathology] = working_tb_df['findings'].apply(lambda x: 1. if pathology in x else 0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRx4Szgb7ieY"
      },
      "outputs": [],
      "source": [
        "diseased_df = working_df[working_df['findings'] != 'No Finding']\n",
        "diseases_dict = {}\n",
        "for i in PATHOLOGY_LIST:\n",
        "  _df = working_df.loc[working_df['findings'].str.contains(i, case = False)]\n",
        "  diseases_dict.update({i:_df})\n",
        "\n",
        "no_findings_df = working_df.loc[working_df['findings'] == 'No Finding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVT8yIxo7ieY"
      },
      "outputs": [],
      "source": [
        "class_probabilities = []\n",
        "for i in PATHOLOGY_LIST:\n",
        "  class_probabilities.append(working_df.loc[:,i].sum() / len(working_df))\n",
        "class_probabilities = np.array(class_probabilities, dtype = 'float32')\n",
        "sns.barplot(x = PATHOLOGY_LIST, y = class_probabilities)\n",
        "plt.xticks(rotation = 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnNcKfVV7ieY"
      },
      "outputs": [],
      "source": [
        "augmented_df = working_df.copy()\n",
        "for disease_name, df in diseases_dict.items():\n",
        "  df_len = len(df)\n",
        "  if disease_name in ['Cardiomegaly','Emphysema','Edema','Fibrosis']:\n",
        "    sample = df.sample(frac = 3,replace = True)\n",
        "  elif disease_name in ['Pneumothorax','Mass',]:\n",
        "    sample = df.sample(frac = 2.2, replace = True)\n",
        "  elif disease_name in ['Effusion','Atelectasis']:\n",
        "    sample = df.sample(frac = .6, replace = True)\n",
        "  # else:\n",
        "    # sample = df.sample(frac = 0.2, replace = True)\n",
        "  augmented_df = pd.concat((augmented_df, sample), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osIQUUNZ7ieY"
      },
      "outputs": [],
      "source": [
        "class_probabilities = []\n",
        "for i in PATHOLOGY_LIST:\n",
        "  class_probabilities.append(augmented_df.loc[:,i].sum() / len(augmented_df))\n",
        "class_probabilities = np.array(class_probabilities, dtype = 'float32')\n",
        "sns.barplot(x = PATHOLOGY_LIST, y = class_probabilities)\n",
        "plt.xticks(rotation = 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeExThk60mSo"
      },
      "outputs": [],
      "source": [
        "augmented_df = augmented_df.replace((np.inf, -np.inf), np.nan)\n",
        "augmented_df = augmented_df.dropna(axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWqASSy81iRH"
      },
      "outputs": [],
      "source": [
        "augmented_df = augmented_df[augmented_df.ct_ratio > 0]\n",
        "augmented_df = augmented_df[augmented_df.ct_ratio < 10]\n",
        "augmented_df = augmented_df.reset_index(drop = True)\n",
        "hernia = augmented_df[augmented_df['findings'] == 'Hernia']\n",
        "augmented_df = augmented_df.drop(index = hernia.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nph1FZxtFXs2"
      },
      "source": [
        "####Trying shit out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_3E7ksKFZHh"
      },
      "outputs": [],
      "source": [
        "imgs = working_df[working_df['findings'].str.contains('Consolidation')]['path'].values\n",
        "fig, ax  = plt.subplots(5,5,figsize = (30,30))\n",
        "ax = ax.flatten()\n",
        "for i in range(25):\n",
        "  img = np.random.choice(imgs)\n",
        "  img = read_image(img, ImageReadMode.GRAY)\n",
        "  ax[i].imshow(img[0], cmap = 'gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rk1xMos5Pd5"
      },
      "source": [
        "#Maybe Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8x15byfbCeB"
      },
      "source": [
        "####All the dropping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNv-YTDkdpDQ"
      },
      "outputs": [],
      "source": [
        "follow_up_patients = working_df['pt_id'].value_counts().index.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E3X1weesmaF"
      },
      "source": [
        "So that I dont forget, the following patients are the ones in which im seeing all the cases which were labeled No finding and among them I have realised that the ones in the first are the ones which have no finding and all the others are bad.\n",
        "\n",
        "In bekar_id all the xrays seem to be bad, and I can either discard the no findings of these or change them into the findings there are in the counter part.\n",
        "\n",
        "In last good, the last of the xrays are better and jsut have to -1 for them\n",
        "\n",
        "Remember that even for the ones whose inital cxr are fine, we can also go and check if we can get some relevant cxr to our problem514\n",
        "\n",
        "did cases till 550"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY9zpeDd8HcI"
      },
      "outputs": [],
      "source": [
        "i = 922"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxxRipMw_WLT"
      },
      "outputs": [],
      "source": [
        "def open_cxr_file(file):\n",
        "  with open(file, 'r') as f:\n",
        "    open_cxr = f.read().split('\\n')\n",
        "  open_cxr = open_cxr[:-1]\n",
        "  open_cxr = set(open_cxr)\n",
        "  open_cxr = np.array([*open_cxr])\n",
        "  open_cxr = open_cxr.astype('int')\n",
        "  return open_cxr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Dgoyf0Svb69"
      },
      "outputs": [],
      "source": [
        "last_cxr_file = BASE_FOLDER + '/updated_last_cxr.txt'\n",
        "with open(last_cxr_file, 'a') as f:\n",
        "      f.write(str(patient_id)+'\\n')\n",
        "last_cxr = open_cxr_file(last_cxr_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMS0QKGyvXKT"
      },
      "outputs": [],
      "source": [
        "worst_cxr_file = BASE_FOLDER + '/updated_worst_cxr.txt'\n",
        "with open(worst_cxr_file, 'a') as f:\n",
        "      f.write(str(patient_id)+'\\n')\n",
        "worst_cxr = open_cxr_file(worst_cxr_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENbmUPlKjhm8"
      },
      "outputs": [],
      "source": [
        "well = working_df[working_df['pt_id'] == follow_up_patients[i]]\n",
        "all_cxr = len(well)\n",
        "no_finding_cxr = len(well[well['findings'] == 'No Finding'])\n",
        "finding_cxr = well[well['findings'] != 'No Finding']['findings'].value_counts()\n",
        "\n",
        "try:\n",
        "  wellwell = well[well['findings'] == 'No Finding']['path'].values[0]\n",
        "  wellwellmiddle = well[well['findings'] == 'No Finding']['path'].values[no_finding_cxr // 2]\n",
        "  wellwelllast = well[well['findings'] == 'No Finding']['path'].values[-1]\n",
        "  fig, ax = plt.subplots(1,3, figsize = (25,12))\n",
        "  patient_id = follow_up_patients[i]\n",
        "  ax[0].imshow(read_image(wellwell)[0,:], cmap = 'gray')\n",
        "  ax[1].imshow(read_image(wellwellmiddle)[0,:], cmap = 'gray')\n",
        "  ax[2].imshow(read_image(wellwelllast)[0,:], cmap = 'gray')\n",
        "  plt.show()\n",
        "  print('total cxr',len(well))\n",
        "  print('normal cxr',no_finding_cxr)\n",
        "  print('patient_id',patient_id)\n",
        "  print('Current_index',i)\n",
        "  print('Different Diseases => \\n',finding_cxr)\n",
        "  already = patient_id in [*worst_cxr, *last_cxr]\n",
        "  print('already seen this patient') if already else None\n",
        "  i += 1\n",
        "except IndexError as e:\n",
        "  print(\"No normal xrays\")\n",
        "  i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKmH8WjDEKfi"
      },
      "outputs": [],
      "source": [
        "sick_pt_id = worst_cxr[np.random.randint(0,len(worst_cxr))]\n",
        "_df = working_df[working_df['pt_id'] == 12880]\n",
        "nf_cxr = _df[_df['findings'] == 'No Finding']\n",
        "f_cxr = _df[_df['findings'] != 'No Finding']\n",
        "n = len(_df)\n",
        "nf_n = len(nf_cxr)\n",
        "f_n = len(f_cxr)\n",
        "\n",
        "print('Total Cxr = {}, nf_cxr = {}, f_cxr = {}, Percentage NF = {:.2f}%  '.format(n, nf_n, f_n, nf_n / n * 100) )\n",
        "all_findings = f_cxr['findings'].values\n",
        "all_findings = '|'.join(all_findings).split('|')\n",
        "all_findings = pd.Series(all_findings)\n",
        "n_findings = all_findings.size\n",
        "findings = all_findings.value_counts()\n",
        "perc_findings = findings / n_findings * 100\n",
        "print('Total Number of Findings = ', n_findings)\n",
        "pd.concat((perc_findings, findings), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXe8FH5BJ4Fa"
      },
      "outputs": [],
      "source": [
        "temp_df = nf_cxr.sample(frac = 1)\n",
        "x = 25\n",
        "fig, ax = plt.subplots(3,3,figsize = (x,x))\n",
        "ax = ax.flatten()\n",
        "for i in range(9):\n",
        "  img = temp_df['path'].values[i]\n",
        "  pos = temp_df['position'].values[i]\n",
        "  finding = temp_df['findings'].values[i]\n",
        "  img = process_img(img)\n",
        "  ax[i].imshow(img, cmap  = 'gray')\n",
        "  ax[i].set_title((pos, finding))\n",
        "  ax[i].axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4WJP7cwn5p"
      },
      "source": [
        "#Making Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7_Z54l_YpLB"
      },
      "source": [
        "###Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RCpm7pYkOSw"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise(nn.Module):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "random_transforms = torch.nn.Sequential(\n",
        "    T.RandomAutocontrast(0.2), \n",
        "    T.RandomAffine(\n",
        "        degrees = 15,\n",
        "        translate =  (.09,.09),\n",
        "        scale = (.86, 1.20),\n",
        "        shear =  9\n",
        "    ),\n",
        "    AddGaussianNoise(0,0.013)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zktXSVNVtA6U"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise(nn.Module):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        super().__init__()\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "class CustomCXRDataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, transform = None, if_numerical_labels : bool = True, numeric_means = None,numeric_stds = None, if_isolate_lung = False):\n",
        "    super().__init__()\n",
        "    self.img_path = df.path.values\n",
        "    self.if_numerical_labels = if_numerical_labels\n",
        "    self.labels = torch.as_tensor(df.loc[:,PATHOLOGY_LIST].values)\n",
        "    self.numeric_means = numeric_means\n",
        "    self.numeric_stds = numeric_stds\n",
        "    self.numeric_data = self.normalized_numeric_data(torch.Tensor(df.loc[:,numerical_cols].values))\n",
        "    self.transform = transform\n",
        "\n",
        "  def normalized_numeric_data(self, data):\n",
        "    if self.numeric_means != None or self.numeric_stds != None:\n",
        "      return (data - self.numeric_means) / self.numeric_stds\n",
        "    means = data.mean(0)\n",
        "    stds = data.std(0)\n",
        "    assert len(means) == data.shape[-1]\n",
        "    numeric_data = (data - means) / stds\n",
        "    self.numeric_means = means\n",
        "    self.numeric_stds = stds\n",
        "    return numeric_data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_path)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = read_image(self.img_path[idx], ImageReadMode.GRAY).float()\n",
        "    image = torch.mul(image, 1/255.)\n",
        "    image = self.transform(image) if self.transform else image\n",
        "    image = torch.cat([image,image,image])\n",
        "    label = self.labels[idx]\n",
        "\n",
        "    if self.if_numerical_labels == False:\n",
        "      return image, label\n",
        "    else:\n",
        "      numeric = self.numeric_data[idx]\n",
        "      return image, numeric, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrlnFKTQvMo_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "SEED = 1005\n",
        "CURRENT_DF = augmented_df\n",
        "\n",
        "train_df, _interim_df = train_test_split(CURRENT_DF, test_size=0.15, random_state = SEED)\n",
        "val_df, test_df = train_test_split(_interim_df, test_size=0.4, random_state = SEED)\n",
        "\n",
        "train_df = pd.concat((train_df, working_vin_df, working_tb_df), axis = 0)\n",
        "train_df = train_df[train_df.ct_ratio > 0.1]\n",
        "\n",
        "train_ds = CustomCXRDataset(train_df, transform = random_transforms, if_isolate_lung=False)\n",
        "val_ds = CustomCXRDataset(val_df, transform = False, numeric_means = train_ds.numeric_means, numeric_stds = train_ds.numeric_stds,if_isolate_lung=False)\n",
        "test_ds = CustomCXRDataset(test_df, transform = False,numeric_means = train_ds.numeric_means, numeric_stds = train_ds.numeric_stds,if_isolate_lung=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True, pin_memory=False, num_workers=6, prefetch_factor=  4)\n",
        "val_dataloader = DataLoader(val_ds, batch_size = BATCH_SIZE, shuffle = False,pin_memory = False,num_workers=6, prefetch_factor = 4)\n",
        "test_dataloader = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = False,num_workers=8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YV2wrOtOwIpu"
      },
      "outputs": [],
      "source": [
        "imgs, numeric,labels = next(iter(train_dataloader))\n",
        "fig, ax = plt.subplots(3,3,figsize = (20,20))\n",
        "ax = ax.flatten()\n",
        "for i in range(9):\n",
        "  ax[i].imshow(imgs[i,0,:,:], cmap = 'gray')\n",
        "  ax[i].set_title(numeric[i][:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTJ_I6SjcQub"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFhrKnyorSIr"
      },
      "outputs": [],
      "source": [
        "feature_extractor = models.efficientnet_b5(pretrained = True)\n",
        "\n",
        "aux_data_nn = nn.Sequential(\n",
        "    nn.Linear(len(numerical_cols), len(numerical_cols)),\n",
        "    nn.SiLU(),\n",
        ")\n",
        "\n",
        "conv_net = nn.Sequential(\n",
        "    feature_extractor.features,\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        ")\n",
        "feature_extractor.classifier[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnLj9u9jLcWZ"
      },
      "outputs": [],
      "source": [
        "!pip install -qq validators\n",
        "!pip install -qq timm==0.5.4\n",
        "model_type = \"GPUNet-D1\" # select one from above\n",
        "precision = \"fp32\" # select either fp32 of fp16 (for better performance on GPU)\n",
        "\n",
        "gpunet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_gpunet', pretrained=True, model_type=model_type, model_math=precision)\n",
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')\n",
        "gpunet.train()\n",
        "\n",
        "gpunet_classifier = gpunet.network[-1].net[:-1]\n",
        "conv_net = nn.Sequential(\n",
        "    gpunet.network[:-1],\n",
        "    gpunet_classifier\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAgzc42tK27s"
      },
      "outputs": [],
      "source": [
        "well.net[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MqZHTbhJFaL"
      },
      "outputs": [],
      "source": [
        "imgs = imgs.cuda()\n",
        "gpunet= gpunet.cuda()\n",
        "with torch.no_grad():\n",
        "  preds = conv_net(imgs)\n",
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heTAVgt91qLV"
      },
      "outputs": [],
      "source": [
        "feature_extractor = models.convnext_large(pretrained = True)\n",
        "\n",
        "conv_net = nn.Sequential(\n",
        "    feature_extractor.features,\n",
        "    feature_extractor.avgpool,\n",
        "    feature_extractor.classifier[:2],\n",
        "    nn.Dropout(0.3)\n",
        ")\n",
        "feature_extractor.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cz5NRNZCuen"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/d-li14/efficientnetv2.pytorch.git\n",
        "!cp ./efficientnetv2.pytorch/effnetv2.py ./effnetv2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-eYKa43ERnZ"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import EfficientNet_V2_M_Weights\n",
        "feature_extractor = models.efficientnet_v2_m(weight = EfficientNet_V2_M_Weights.IMAGENET1K_V1)\n",
        "\n",
        "aux_data_nn = nn.Sequential(\n",
        "    nn.Linear(len(numerical_cols), len(numerical_cols)),\n",
        "    nn.SiLU(),\n",
        ")\n",
        "\n",
        "conv_net = nn.Sequential(\n",
        "    feature_extractor.features,\n",
        "    feature_extractor.avgpool,\n",
        "    feature_extractor.classifier[:-1]\n",
        ")\n",
        "\n",
        "feature_extractor.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuZh8LsKrRlC"
      },
      "outputs": [],
      "source": [
        "class CXR_Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CXR_Net, self).__init__()\n",
        "    self.conv_net = conv_net\n",
        "    self.combined_seq = nn.Sequential(\n",
        "        nn.Linear(1280 + len(numerical_cols), 512),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(512, len(PATHOLOGY_LIST))\n",
        "        )\n",
        "\n",
        "  def forward(self, img, numeric):\n",
        "    img_features = self.conv_net(img)\n",
        "    size = img_features.shape\n",
        "    img_features = img_features.view((size[0], size[1]))\n",
        "    combined = torch.cat((img_features, numeric), 1)\n",
        "    z = self.combined_seq(combined)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_MP0byzMdga"
      },
      "outputs": [],
      "source": [
        "pos_weights = np.sum(train_df.loc[:,PATHOLOGY_LIST].values, axis = 0) / len(train_df)\n",
        "pos_weights = torch.tensor(pos_weights)\n",
        "neg_weights = 1 - pos_weights\n",
        "imratio = neg_weights / pos_weights\n",
        "imratio = imratio.float().cuda()\n",
        "imratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqIZZk6k3TVx"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load('./drive/MyDrive/Models/nih_full/b4_sgd_cropped_moment')\n",
        "model = CXR_Net()\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saOJAXzNnPwo"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 35\n",
        "LEARNING_RATE = 2e-3\n",
        "use_amp = True\n",
        "\n",
        "model = CXR_Net().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE,)\n",
        "# optimizer = torch.optim.Adadelta(model.parameters(), )\n",
        "loss_fn = nn.BCEWithLogitsLoss(pos_weight = imratio,reduction = 'sum').to(device)\n",
        "scaler = torch.cuda.amp.grad_scaler.GradScaler(enabled=use_amp)\n",
        "# lr_schedule = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n",
        "lr_schedule = torch.optim.lr_scheduler.MultiStepLR(optimizer, [13,25,], gamma=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXY7w-vIEOh7"
      },
      "outputs": [],
      "source": [
        "configs.update(\n",
        "    {\n",
        "     'epochs' : EPOCHS,\n",
        "     'init_lr' : LEARNING_RATE,\n",
        "     'lr_schedule' : lr_schedule.state_dict,\n",
        "     'mixed_precision' : use_amp,\n",
        "     'architecture' : 'effnet_v2',\n",
        "     'loss' : loss_fn,\n",
        "     'optimizer' : optimizer,\n",
        "     'pos_weights' : imratio,\n",
        "     'batch_size' : BATCH_SIZE,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoenQhLa-V56"
      },
      "source": [
        "#Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6iHBEEa83Bs"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List, Dict\n",
        "\n",
        "class pl_Dataset(pl.LightningDataModule):\n",
        "  \n",
        "  def __init__(\n",
        "      self,\n",
        "      data,\n",
        "      extra_data : List = [],\n",
        "      dataloader_kwargs : Dict = {},\n",
        "      batch_size : int = 32,\n",
        "      img_dims : Tuple[int, int, int] = (1,284,284),\n",
        "      train_val_split : float = .15,\n",
        "      val_test_split: float = .4,\n",
        "      if_numerical_labels: bool = True\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.dataloader_kwargs = dataloader_kwargs\n",
        "    self.save_hyperparameters()\n",
        "    self.transform = self.get_transform()\n",
        "    self.train_df, _interim_df = train_test_split(self.hparams.data, test_size= self.hparams.train_val_split)\n",
        "    self.val_df, self.test_df = train_test_split(_interim_df, test_size= self.hparams.val_test_split)\n",
        "    self.train_df = pd.concat((self.train_df, *self.hparams.extra_data), axis = 0)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    \n",
        "    self.train_df = self.train_df[self.train_df.ct_ratio > 0.1]\n",
        "    \n",
        "    self.train_ds = CustomCXRDataset(self.train_df, transform = self.transform, if_numerical_labels = self.hparams.if_numerical_labels)\n",
        "    self.val_ds = CustomCXRDataset(self.val_df, transform = False, numeric_means = self.train_ds.numeric_means, numeric_stds = self.train_ds.numeric_stds,if_numerical_labels =  self.hparams.if_numerical_labels)\n",
        "    self.test_ds = CustomCXRDataset(self.test_df, transform = False,numeric_means = self.train_ds.numeric_means, numeric_stds = self.train_ds.numeric_stds,if_numerical_labels =  self.hparams.if_numerical_labels)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.train_ds, shuffle = True, batch_size = self.hparams.batch_size, **self.dataloader_kwargs)\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(self.val_ds, shuffle = False, batch_size = self.hparams.batch_size, **self.dataloader_kwargs)\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_ds, shuffle = False, batch_size = self.hparams.batch_size, **self.dataloader_kwargs)\n",
        "\n",
        "  def predict_dataloader(self):\n",
        "    return DataLoader(self.test_ds,shuffle = False, batch_size = self.hparams.batch_size, **self.dataloader_kwargs)\n",
        "  \n",
        "  def get_transform(self):\n",
        "    return T.Compose([\n",
        "          T.RandomAutocontrast(0.2), \n",
        "          T.RandomAffine(\n",
        "              degrees = 15,\n",
        "              translate =  (.09,.09),\n",
        "              scale = (.86, 1.20),\n",
        "              shear =  9\n",
        "          ),\n",
        "          AddGaussianNoise(0,0.013)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQXuY1Et-Zqk"
      },
      "outputs": [],
      "source": [
        "class Classifier(pl.LightningModule):\n",
        "  def __init__(self,\n",
        "              feaute_extractor,\n",
        "              fe_top_params,lr,\n",
        "                num_classes,\n",
        "                num_numerical_cols,\n",
        "                  train_df):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.loss = self.loss_fn(train_df)\n",
        "    self.classifier = nn.Sequential(\n",
        "        conv_net,\n",
        "        # nn.Linear(self.hparams.fe_top_params + self.hparams.num_numerical_cols, 512),\n",
        "        nn.Linear(self.hparams.fe_top_params, 512),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(512, self.hparams.num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    # x = self.hparams.feature_extractor(x)\n",
        "    return self.classifier(x)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    imgs, labels = batch\n",
        "    preds = self(imgs)\n",
        "    loss = self.loss(preds, labels)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    imgs, labels = batch\n",
        "    preds = self(imgs)\n",
        "    loss = self.loss(preds, labels)\n",
        "    self.log(f'val_loss', loss)\n",
        "\n",
        "  def loss_fn(self, train_df):\n",
        "    pos_weights = np.sum(self.hparams.train_df.loc[:,PATHOLOGY_LIST].values, axis = 0) / len(train_df)\n",
        "    pos_weights = torch.tensor(pos_weights)\n",
        "    neg_weights = 1 - pos_weights\n",
        "    imratio = (neg_weights / pos_weights).float()\n",
        "    assert not any(torch.isnan(imratio))\n",
        "    return nn.BCEWithLogitsLoss(pos_weight = imratio,reduction = 'sum')\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.SGD(self.parameters(), lr = self.hparams.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [13,25,], gamma=0.3)\n",
        "    return [optimizer], [scheduler]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Cr1PFXDLDq"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import EfficientNet_V2_M_Weights\n",
        "\n",
        "feature_extractor = models.efficientnet_v2_m(weight = EfficientNet_V2_M_Weights.IMAGENET1K_V1)\n",
        "\n",
        "aux_data_nn = nn.Sequential(\n",
        "    nn.Linear(len(numerical_cols), len(numerical_cols)),\n",
        "    nn.SiLU(),\n",
        ")\n",
        "\n",
        "conv_net = nn.Sequential(\n",
        "    feature_extractor.features,\n",
        "    feature_extractor.avgpool,\n",
        "    feature_extractor.classifier[:-1]\n",
        ")\n",
        "\n",
        "feature_extractor.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0uH2UyYDFYQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "NUMERICAL_LABELS = False\n",
        "\n",
        "dataloader_config = dict(\n",
        "    num_workers = 4,\n",
        "    prefetch_factor = 4,\n",
        ")\n",
        "\n",
        "data_module = pl_Dataset(\n",
        "  data = augmented_df,\n",
        "  extra_data = [working_vin_df, working_tb_df],\n",
        "  batch_size = 32,\n",
        "  dataloader_kwargs = dataloader_config,\n",
        "  img_dims  = (1,284,284),\n",
        "  if_numerical_labels = NUMERICAL_LABELS,\n",
        ")\n",
        "\n",
        "model = Classifier(\n",
        "  conv_net,\n",
        "  fe_top_params  = 1280,\n",
        "  lr = 1e-3,\n",
        "  num_classes = len(PATHOLOGY_LIST),\n",
        "  num_numerical_cols = len(numerical_cols),\n",
        "  train_df = data_module.train_df\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "  enable_progress_bar = True,\n",
        "  max_epochs = 10,\n",
        "  accelerator = 'auto',\n",
        "  # check_val_every_n_epoch = 1,\n",
        "  # num_sanity_val_steps = 2,\n",
        "  # overfit_batches = 10,\n",
        "  # auto_scale_batch_size = True,\n",
        "  # auto_lr_find = True,\n",
        "  # benchmark = True,\n",
        "  # deterministic = True,\n",
        ")\n",
        "\n",
        "trainer.fit(model, datamodule = data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-0R3Q2iU5Gq"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1,2,3,4])\n",
        "any(torch.isnan(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GF1PprrfILE"
      },
      "source": [
        "###Train Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT9hdsPCyAJy"
      },
      "outputs": [],
      "source": [
        "def print_predictions( imgs,y_pred, y_true):\n",
        "  i = np.random.randint(0,y_true.shape[0] - 1)\n",
        "\n",
        "  true_label = [disease for label, disease in zip(y_true[i], PATHOLOGY_LIST) if label]\n",
        "  true_label = true_label if len(true_label) > 0 else ['No Findings']\n",
        "  true_label = '|'.join(true_label)\n",
        "  sorted_pred = sorted([(disease, label.item()) for label, disease in zip(y_pred[i], PATHOLOGY_LIST)], key = lambda x : x[1], reverse = True)\n",
        "  pred = {disease : label.item() for label, disease in zip(y_pred[i], PATHOLOGY_LIST)}\n",
        "  img = imgs[i]\n",
        "\n",
        "  print(\"True Label is \", true_label)\n",
        "  print(\"Prediction is \", sorted_pred)\n",
        "\n",
        "  return img, pred, true_label\n",
        "\n",
        "def calc_auc_prc(preds, true):\n",
        "  true, preds = true.cpu().detach(), preds.cpu().detach()\n",
        "  weighted_prc_score = metrics.average_precision_score(true, preds, average = 'weighted')\n",
        "  weighted_auc_score = metrics.roc_auc_score(true, preds, average = 'weighted')\n",
        "  return weighted_auc_score, weighted_prc_score\n",
        "\n",
        "def individual_prc_scores(preds, true, job_type = 'train'):\n",
        "  true, preds = true.cpu().detach(), preds.cpu().detach()\n",
        "  individual_prc_score = metrics.average_precision_score(true, preds, average = None)\n",
        "  individual_prc_score = {f'{job_type}_{disease}' : score for disease, score in zip(PATHOLOGY_LIST, individual_prc_score)}\n",
        "  print(individual_prc_score)\n",
        "  wandb.log(individual_prc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkxPdftrqUd6"
      },
      "outputs": [],
      "source": [
        "def save_auc(y_true, y_preds):\n",
        "  fig = plt.figure(figsize = (15,15))\n",
        "  for i in range(len(PATHOLOGY_LIST)):\n",
        "    fpr, tpr , _ = metrics.roc_curve(y_true[:,i], y_preds[:,i])\n",
        "    score = metrics.roc_auc_score(y_true[:,i], y_preds[:,i])\n",
        "    plt.plot(fpr, tpr, label = f'{PATHOLOGY_LIST[i]} - {score:.4f}')\n",
        "    plt.legend()\n",
        "  wandb.log({'auc_curve' : fig})\n",
        "\n",
        "def save_prc(y_true, y_preds):\n",
        "  precision = {}\n",
        "  recall = {}\n",
        "  average_precision = {}\n",
        "  fig = plt.figure(figsize =( 15,15))\n",
        "  for i, disease in enumerate(PATHOLOGY_LIST):\n",
        "    precision[disease], recall[disease], thresh = metrics.precision_recall_curve(y_true[:,i], y_preds[:,i])\n",
        "    average_precision[disease] = metrics.average_precision_score(y_true[:,i], y_preds[:,i])\n",
        "    plt.plot(recall[disease], precision[disease], label = f'{disease} - {average_precision[disease]:.4f}')\n",
        "    plt.legend()\n",
        "    # plt.title(f'PRC Curve - {wandb.run.name} ')\n",
        "  wandb.log({'prc_curve' : fig})\n",
        "\n",
        "def read_torch_img(file):\n",
        "  img = read_image(file).float()\n",
        "  img /= 255.\n",
        "  resize = T.Resize(IMG_SIZE[:2])\n",
        "  img = resize(img)\n",
        "  return img[None,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5mJcNAvKPJR"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, lr_scheduler, logging_freq = 200):\n",
        "  global lr\n",
        "  total_samples = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  cum_test = None\n",
        "  cum_preds = None\n",
        "  LOGGING_FREQ = logging_freq\n",
        "  avg_loss = []\n",
        "  avg_prc = []\n",
        "  for batch, (img,numeric_data,true_labels) in enumerate(dataloader):\n",
        "    img,numeric_data,true_labels=img.to(device),numeric_data.to(device),true_labels.to(device)\n",
        "    if batch % LOGGING_FREQ == 0: batch_start = perf_counter()\n",
        "\n",
        "    with torch.cuda.amp.autocast(enabled = use_amp):\n",
        "      pred = model(img, numeric_data)\n",
        "      loss = loss_fn(pred, true_labels)\n",
        "    # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "    scaler.scale(loss).backward()\n",
        "\n",
        "    # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "    # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
        "    # otherwise, optimizer.step() is skipped.\n",
        "    scaler.step(optimizer)\n",
        "\n",
        "    # Updates the scale for neimgt iteration.\n",
        "    scaler.update()\n",
        "\n",
        "    optimizer.zero_grad(set_to_none = True)\n",
        "\n",
        "    if batch % LOGGING_FREQ == 0:\n",
        "      time_per_batch = (perf_counter() - batch_start)\n",
        "      loss, current = loss.item(), batch * len(img)\n",
        "      avg_loss.append(loss)\n",
        "      wandb.log({'train_loss' : np.mean(avg_loss)}, commit = False)\n",
        "      print(f\"loss: {np.mean(avg_loss):>7f}  [{current:>5d}/{total_samples:>5d}], Time/Batch: {time_per_batch:.3f}\")\n",
        "      \n",
        "      if batch % (LOGGING_FREQ*5) == 0:\n",
        "        cum_preds = pred if cum_preds == None else torch.cat((cum_preds, pred), axis = 0,)\n",
        "        cum_test = true_labels if cum_test == None else torch.cat((cum_test, true_labels), 0)\n",
        "        try:\n",
        "          auc, prc = calc_auc_prc(cum_preds, cum_test)\n",
        "          individual_prc_scores(cum_preds, cum_test)\n",
        "          avg_prc.append(prc)\n",
        "          prc = np.mean(avg_prc)\n",
        "          print(f'Weighted AUC = {auc:.4f}, Weighted PRC = {prc:.4f}')\n",
        "          wandb.log({'auc' : auc, 'prc' : prc}, commit = False)\n",
        "        except ValueError:\n",
        "          print('Value Error, passing ...')\n",
        "        except TypeError:\n",
        "          print('Type Erro, passisng')\n",
        "\n",
        "  if lr_scheduler:\n",
        "    lr_scheduler.step()\n",
        "    lr = lr_scheduler.get_last_lr()\n",
        "  wandb.log({'lr' : lr}, commit  = False)\n",
        "\n",
        "  \n",
        "\n",
        "def val_loop(dataloader, model, loss_fn, save = True):\n",
        "  global eval_metric\n",
        "  total_samples = len(dataloader.dataset)\n",
        "  model.eval()\n",
        "  loss = 0\n",
        "\n",
        "  cum_test = None\n",
        "  cum_preds = None\n",
        "  avg_loss = []\n",
        "  for batch, (imgs,numeric_data, true_labels) in enumerate(dataloader):\n",
        "    imgs,numeric_data,true_labels=imgs.to(device),numeric_data.to(device),true_labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      preds = model(imgs, numeric_data)\n",
        "      loss += loss_fn(preds, true_labels)\n",
        "\n",
        "    cum_preds = preds if cum_preds == None else torch.cat((cum_preds, preds), axis = 0,)\n",
        "    cum_test = true_labels if cum_test == None else torch.cat((cum_test, true_labels), 0)\n",
        "\n",
        "  # Calculating Metrics\n",
        "  try:\n",
        "    auc, prc = calc_auc_prc(cum_preds, cum_test)\n",
        "    individual_prc_scores(cum_preds, cum_test, job_type = 'val')\n",
        "\n",
        "    print(f'Weighted AUC = {auc:.4f}, Weighted PRC = {prc:.4f} ')\n",
        "    wandb.log({'val_auc' : auc, 'val_prc' : prc}, commit = False)\n",
        "  except ValueError as e:\n",
        "    print('Welp seems something happend')\n",
        "    \n",
        "  # Getting the loss\n",
        "  loss = loss / (batch + 1)\n",
        "  loss = loss.item()\n",
        "  wandb.log({'val_loss' : loss}, commit = False)\n",
        "  print(f\"loss: {loss:>7f}\")\n",
        "\n",
        "  # Getting PRedictions\n",
        "  img,pred,true_label = print_predictions( imgs, preds, true_labels)\n",
        "  img,pred,true_label = print_predictions( imgs, preds, true_labels)\n",
        "  if epoch > 5:\n",
        "    table.add_data(epoch, wandb.Image(img), true_label, pred)\n",
        "\n",
        "  if prc > eval_metric:\n",
        "    eval_metric = prc\n",
        "    print('Best Model Yet !!!')\n",
        "    run_name = run.name\n",
        "    if save : \n",
        "      print('Saving Model')\n",
        "      torch.save(model.state_dict(), f'./{run_name}.pth')\n",
        "      os.system(f'cp ./{run_name}.pth ./drive/MyDrive/Models/nih_full/{run_name}.pth')\n",
        "\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model):\n",
        "  test_preds = torch.Tensor().to(device)\n",
        "  test_labels = torch.Tensor().to(device)\n",
        "  model.eval()\n",
        "  for img, numeric_data,labels in dataloader:\n",
        "    img,numeric_data,labels=img.to(device),numeric_data.to(device),labels.to(device)\n",
        "    with torch.no_grad():\n",
        "\n",
        "      preds = model(img,numeric_data)\n",
        "      test_preds = torch.cat((test_preds, preds), 0)\n",
        "      test_labels = torch.cat((test_labels, labels), 0)\n",
        "\n",
        "  y_true, y_preds = test_labels.cpu() ,test_preds.cpu()\n",
        "  save_auc(y_true, y_preds)\n",
        "  save_prc(y_true, y_preds)\n",
        "\n",
        "  # custom_cxr = wandb.Table(columns = ['image', 'predictions'])\n",
        "  # TB_CXR = './drive/MyDrive/tb_ambala_cxr/'\n",
        "  # cxrs = np.random.choice(os.listdir(TB_CXR), 30)\n",
        "  # for cxr in cxrs:\n",
        "  #   cxr = os.path.join(TB_CXR, cxr)\n",
        "  #   img = read_torch_img(cxr)\n",
        "  #   with torch.no_grad():\n",
        "  #     img = img.cuda()\n",
        "  #     pred = model(img)\n",
        "  #   pred_dict = {disease:value.item() for disease, value in zip(PATHOLOGY_LIST, pred[0])}\n",
        "  #   custom_cxr.add_data(wandb.Image(img[0]), pred_dict)\n",
        "  # wandb.log({'custom_predictions' : custom_cxr})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSOeQcAwfFH2"
      },
      "source": [
        "###Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jtT6NBwtpNPK"
      },
      "outputs": [],
      "source": [
        "from time import perf_counter\n",
        "\n",
        "with wandb.init(name = 'effnet_v2', project = 'nih_full_pytorch',group='V2',config=configs) as run:\n",
        "  # wandb.watch(model, log_freq = 1000, log = 'all', log_graph = True,)\n",
        "  table = wandb.Table(columns = ['epoch','image', 'label', 'prediction'], allow_mixed_types=True)\n",
        "  eval_metric = 0\n",
        "  lr = LEARNING_RATE\n",
        "  for epoch in range(EPOCHS):\n",
        "    wandb.log({'epoch' : epoch}, commit = False)\n",
        "    start = perf_counter()\n",
        "\n",
        "    print(f\"Starting {epoch + 1} epoch \\n-------------------------------- \")\n",
        "    print('Learning Rate = ', lr)\n",
        "\n",
        "    print('Starting Training \\n---------------------')\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer, lr_schedule, 300)\n",
        "\n",
        "    print('Validating \\n---------------------')\n",
        "    val_loop(val_dataloader, model, loss_fn, save = True)\n",
        "\n",
        "    epoch_time =  perf_counter() - start\n",
        "\n",
        "    wandb.log({'epoch_time' : epoch_time}, commit = True)\n",
        "    print('Time taken => ',epoch_time)\n",
        "    print('===================================\\n')\n",
        "\n",
        "  wandb.log({'predictions_table' : table})\n",
        "  test_loop(test_dataloader, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FmUMaKfu0x"
      },
      "source": [
        "ABle to plo these things easily now the plan is to delete the prior stuff, get a proper pipeline for interpretation and also testing all the data with a testing function at the end. Can put that in the finally section so that no matter what happens, the interpretation will be saved.\n",
        "\n",
        "After that we can goa nd get onto the big bouys.\n",
        "\n",
        "Also, see that the predictions made are coming out fine.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV2qNEiSi0gK"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKxpbQnd4GHP"
      },
      "outputs": [],
      "source": [
        "# model = feature_extractor.cuda()\n",
        "test_preds = torch.Tensor().to(device)\n",
        "test_labels = torch.Tensor().to(device)\n",
        "model = model.cuda()\n",
        "for img, numeric_data, labels in test_dataloader:\n",
        "  with torch.no_grad():\n",
        "    img, numeric_data, labels = img.to(device),numeric_data.to(device), labels.to(device)\n",
        "    preds = model(img, numeric_data)\n",
        "    test_preds = torch.cat((test_preds, preds), 0)\n",
        "    test_labels = torch.cat((test_labels, labels), 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj26OYx2FPI0"
      },
      "outputs": [],
      "source": [
        "y_preds, y_true = test_preds.cpu().numpy(), test_labels.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ2TYMdzLrsH"
      },
      "outputs": [],
      "source": [
        "i = np.random.randint(0, len(test_ds))\n",
        "y_preds[i], y_true[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-oRClsDPrCD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "fig = plt.figure(figsize = (15,15))\n",
        "for i in range(len(PATHOLOGY_LIST)):\n",
        "  fpr, tpr , _ = roc_curve(y_true[:,i], y_preds[:,i])\n",
        "  score = roc_auc_score(y_true[:,i], y_preds[:,i])\n",
        "  plt.plot(fpr, tpr, label = f'{PATHOLOGY_LIST[i]} - {score}')\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEWp_4ndd1_5"
      },
      "outputs": [],
      "source": [
        "precision = {}\n",
        "recall = {}\n",
        "thresh = {}\n",
        "average_precision = {}\n",
        "fig = plt.figure(figsize =( 15,15))\n",
        "for i, disease in enumerate(PATHOLOGY_LIST):\n",
        "  precision[disease], recall[disease], thresh[disease] = metrics.precision_recall_curve(y_true[:,i], y_preds[:,i])\n",
        "  average_precision[disease] = metrics.average_precision_score(y_true[:,i], y_preds[:,i])\n",
        "  plt.plot(recall[disease], precision[disease], label = f'{disease} - {average_precision[disease]:.4f}')\n",
        "  plt.legend()\n",
        "  # plt.title(f'PRC Curve - {wandb.run.name} ')\n",
        "# plt.plot()\n",
        "# fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T38TeueWL3Xn"
      },
      "outputs": [],
      "source": [
        "func_thresh = {}\n",
        "for (disease, threshold), rec, prec in zip(thresh.items(), recall.values(), precision.values()):\n",
        "  print(disease, len(threshold), len(rec), len(prec))\n",
        "  zipped_rec_prec = list(zip(rec, prec))\n",
        "  print(max(zipped_rec_prec, key = lambda x: 2.5 * x[0] + x[1]))\n",
        "  max_values = max(list(zip(rec, prec)), key = lambda x: 1.5 * x[0] + x[1])\n",
        "  idx = zipped_rec_prec.index(max_values)\n",
        "  func_thresh[disease] = threshold[idx]\n",
        "  print(func_thresh[disease])\n",
        "  print('====================================')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaR4qA1lI3NB"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize =( 15,15))\n",
        "for disease, thresholds in thresh.items():\n",
        "  plt.plot(range(len(thresholds)), thresholds, label = disease)\n",
        "  j = 14000\n",
        "  try:\n",
        "    print(disease, thresholds[j], precision[disease][j], recall[disease][j], len(thresholds))\n",
        "  except IndexError:\n",
        "    pass\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yde9tDM2Mbs5"
      },
      "outputs": [],
      "source": [
        "def read_torch_img(file):\n",
        "  img = read_image(file).float()\n",
        "  img /= 255.\n",
        "  resize = T.Resize(IMG_SIZE[:2])\n",
        "  img = resize(img)\n",
        "  return img[None,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6sjWqkTbGax"
      },
      "outputs": [],
      "source": [
        "!cp -r ./drive/MyDrive/cxr_segment ./cxr_segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXCP6aEjdE5h"
      },
      "outputs": [],
      "source": [
        "!cp -r ./cxr_segment ./drive/MyDrive/cxr_segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HrbcdcrgqS3"
      },
      "outputs": [],
      "source": [
        "from cxr_segment.segmentation_model import Segmentation_Model\n",
        "from cxr_segment.feature_extraction import LungIntepretation\n",
        "\n",
        "def get_lung_boundaries(file_path):\n",
        "  segment_model = Segmentation_Model()\n",
        "  mask = segment_model.get_mask_from_file(file_path)\n",
        "\n",
        "  lung_interpret = LungIntepretation(mask)\n",
        "  return lung_interpret.get_cxr_boundaries\n",
        "\n",
        "def mask_img(img):\n",
        "  mask = torch.zeros((IMG_SIZE[:2]))\n",
        "  # min(top) = max(self.top[idx], 0)\n",
        "  # bottom = min(self.bottom[idx], IMG_SIZE[0])\n",
        "  # left = max(self.left[idx], 0)\n",
        "  # right = min(self.right[idx], IMG_SIZE[0])\n",
        "  top, bottom, left, right = get_lung_boundaries(cxr)\n",
        "  # print(top,bottom, left, right)\n",
        "  top, bottom, left, right = min(top) * 354 // 256 , max(bottom)* 414 // 256, min(left)* 324 // 256 , max(right)* 414 // 256\n",
        "  mask[top: bottom, left : right] = 1\n",
        "  return img *  mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y9Q6A6Wjzt7"
      },
      "outputs": [],
      "source": [
        "from cxr_segment import get_numeric_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZZLZJe6i5we"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load('./drive/MyDrive/Models/nih_full/b5/b5_93_9prc.pth')\n",
        "model = CXR_Net()\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_lrCXb5M8O3"
      },
      "outputs": [],
      "source": [
        "TB_CXR = './drive/MyDrive/tb_ambala_cxr/'\n",
        "cxrs = np.random.choice(os.listdir(TB_CXR))\n",
        "cxr = os.path.join(TB_CXR, cxrs)\n",
        "img = read_torch_img(cxr)\n",
        "numeric = get_numeric_data(cxr)\n",
        "numeric = torch.tensor(numeric, dtype = torch.float32)\n",
        "numeric_means = torch.tensor([0.47789281606674194,\n",
        "0.3418794870376587,\n",
        "60.031524658203125,\n",
        "59.270320892333984,\n",
        "0.9683226346969604,\n",
        "0.935834527015686,\n",
        "1.206820726394653,\n",
        "0.9691731333732604])\n",
        "\n",
        "numeric_stds = torch.tensor([0.12098916620016098,\n",
        "0.10514690726995468,\n",
        "18.826292037963867,\n",
        "18.78540802001953,\n",
        "0.11661211401224136,\n",
        "0.267573744058609,\n",
        "2.147334337234497,\n",
        "0.2273915410041809])\n",
        "model.eval()\n",
        "numeric = (numeric - numeric_means) / numeric_stds\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(img[0,0,:,:], cmap = 'gray')\n",
        "with torch.no_grad():\n",
        "  img, numeric = img.to(device), numeric.to(device)\n",
        "  pred = model(img, numeric[None,:])\n",
        "pred_numpy = pred.cpu().numpy()[0]\n",
        "# func_thresh_list = [func_thresh[disease] for disease in PATHOLOGY_LIST]\n",
        "# np.array((PATHOLOGY_LIST, func_thresh_list, pred_numpy, pred_numpy > func_thresh_list)).T\n",
        "np.array((PATHOLOGY_LIST, pred_numpy)).T, numeric"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "g06LLJBwwZyM",
        "cITDXG3kt6-7",
        "nZrwct_W36cK",
        "NOdnnoxeBIXm",
        "O61YQUZz7ieX",
        "tb69E4A0LWWd",
        "Nph1FZxtFXs2",
        "6rk1xMos5Pd5",
        "y8x15byfbCeB",
        "p7_Z54l_YpLB",
        "1GF1PprrfILE",
        "eV2qNEiSi0gK"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Dp8S4Tlm-2zJtIZkLm0okkO9SRXwG-KT",
      "authorship_tag": "ABX9TyMHYDL0OO4EQGYsTCw2mNDP",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}